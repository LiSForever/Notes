### 枚举内容与功能

#### 页面抓取工作

##### 主动扫描

* web爬取工具：目前有许多自动爬取页面的爬虫工具，它们既可以根据页面里的链接迭代查询，还可以抓取部分JavaScript中的链接，但也存在较大局限性

  * 无法处理不常用导航机制，例如复杂JavaScript代码动态建立和处理的菜单
  * 对输入严格限制的表单
  * 基于表单和query参数的导航机制，例如/account.jsp?action=根据不同的参数返回截然不同的页面；或则一个表单，根据其提交的不同内容内容
  * 一些程序在url中插入包含定时器和随机数种子的混淆内容，这会造成爬虫重复爬取同一个页面或者因为无法判断是否是新的页面而爬取失败
  * 应用程序采取了身份验证机制，这可能会造成
    * 有时会话的令牌管理较为复杂，爬虫无法自动进行令牌更新，导致会话终止
    * 抓取到某些注销登录的功能，中断会话
    * 向敏感功能提交无效输入，应用程序出于防御中断会话
  * **爬取了某些危险操作**，例如进行了账户密码修改、资源删除等操，这会对目标站点造成难以预料的后果

* 值得注意的文件和目录

  * robots.txt：该文件下常常有目标站点不希望我们爬取的敏感目录和内容。下面是一个开源的博客系统，emlog，这是它的robots.txt，它显示出的/admin/和/config.php显然是敏感目录。

  ![image-20231001153426259](.\images\image-20231001153426259.png)

  * 站点地图：Sitemap.html、baiduSitemap.html等页面。站点地图是一种文件，它的存在一般为了搜索引擎能够更好地抓取页面，该站点的搜索排名，根据这个文件，我们能够很快的了解目标站点的主要功能。

  ![image-20231001210922237](.\images\image-20231001210922237.png)

  ![image-20231001211028617](.\images\image-20231001211028617.png)

##### 基于表单的导航和REST风格

* 基于表单的导航：有许多web应用，对于同一个web页面，例如/account，在提交表单时，提交不同的数据会使服务器端采取不同的方式进行处理，返回完全不同的界面，这在jsp应用和嵌入式设备使用c语言实现的web程序中非常常见。
* 基于query参数的导航：与上面类似
* REST风格的URL：传统url http://localhost:8080/employee/list?id=1，REST URL http://localhost:8080/employees/1，可以看到它们的区别就是REST风格的url会将query参数添加入url。

##### 被动扫描

> 许多主动扫描无法抓取的页面，我们可以通过被动扫描进行抓取，例如使用burpsuite的代理功能，然后正常浏览各个页面，burpsuite将会记录我们浏览过的页面。

#### 搜寻不易抓取内容

> 应用程序常常包含没有直接链接或无法通过可见的主要内容访问的内容和功能，可能包括如下内容：
>
> * 备份文件
> * web应用的描述文件
> * 新添加的功能，处于测试阶段，未在web应用的程序中建立链接
> * 一些对一般用户不可见的功能
> * 尚未从服务器删除的旧版本文件
> * 被遗忘的敏感文件，CA证数、.git、.htaccess服务器配置文件等
>
> 这些内容通过我们的主动爬取和被动爬取都难以抓取到，但是我们可以通过一些其他技巧获得这些页面。

##### 爆破

* dirsearch、dirmap、御剑等：利用字典直接扫描

* burpsuite爆破：可像爆破弱口令一样，指定目录的某个部分进行爆破

  ![image-20231003210336479](.\images\image-20231003210336479.png)

##### 根据已有内容进行推测

> 许多url路径的目录命名方式是有规律的，例如已经发现了 /admin/logout，那打击率会有/admin/login；发现了/pub/media/100，很可能会有/pub/media/101，类似的方法也适用于基于post参数和query参数的导航方式。这种根据已有的目录名进行推测的方法，很适合通过我们手动去验证或者通过burpsuite的爆破模块完成。

##### 利用公开信息

* google等搜索引擎搜索：我们利用搜索引擎的高级语法，搜寻包含目标站点链接的内容，或者使用类似于site: target.com的语法，搜索目标站点的内容。除了利用搜索引擎强大的搜索功能外，还可以利用它们保存的目标站点应用的历史版本，已获得过去的信息。
* web档案：例如www.archive.org等，发现过去的信息
* 从与目标站点相关的网站：可以从目标站点的旁站入手，或者与目标站点相关的论坛
* github等源码托管网站：搜寻目标站点的源码或者搜寻与其相关的项目

##### 利用Web服务器的弱点

> 这一点在这里不多赘述，后续有专门的章节进行分析，在分析目标站点功能和内容的阶段，最常见的缺陷是web服务器设置不当引起的目录遍历。

#### 整理抓取的页面和内容

##### 将抓取的url、参数与相应功能联系起来

##### 分析参数、搜寻隐藏的参数

* 抓取到带有参数的页面后，我们要尝试着根据响应页面分析参数的功能，更改参数的默认数据来发现不同的响应行为
* 一些页面除了存在默认存在的参数，我们还可以尝试着猜测和添加一些其他参数，例如debug=true这样的参数，也可以使用burpsuite的爆破模块来寻找是否有隐藏的参数，但这些比较依赖于运气。

### 分析应用程序

* 应用程序的核心功能
* web应用值得注意的行为：站外链接、错误消息、管理与日志功能、重定向的使用
* 核心安全机制：会话状态、访问控制、验证机制、权限分配
* 用户输入入口点
* 客户端技术
* 服务器端技术

#### 确定用户输入入口点

* query参数
* post提交的参数
* cookie
* http消息头：referer、user-agent、x-forwarded-for等消息头尤其值得注意
* **带外通道**：许多应用程序都有处理其他应用程序传递数据的带外通道，而且往往web应用程序的设计者容易默认带外通道接收到的数据是合规的
  * 处理显示通过SMTP接收到的电子邮件消息的Web邮件应用cheche那个徐
  * 具有通过HTTP从其他放服务器获取内容功能
  * 使用网络嗅探器收集数据，并在Web应用程序界面显示这些数据
  * 任何提供给非浏览器用户使用的API接口
* REST风格url

#### 确定服务器端技术

* 许多Web服务器公开与Web服务器软件本身和所安装组件有关的详细版本信息。例如，HTTP Server消息头揭示大量与安装软件有关的信息：除Server消息头外，下列位置也可能揭露有关软件类型和版本的信息：
  *  建立HTML页面的模板
  * 定制的HTTP消息头
  * URL查询字符串参数
* 确定应用程序使用的开源代码和第三方组件：这些可以通过目标站点的公开信息获得，或者通过HTML**页面中特殊的标志**例如ico标识，或者页面源代码中的某些注释，或者相关的版权信息。我们可以通过fofa等网络空间测绘工具搜索这些内容，以确定更多信息。
* HTTP指纹识别：许多自动识别工具可供使用
* 通过文件扩展名确定web应用程序所使用的技术
  * php
  * pl
  * jsp
  * py
* 通过目录名称确定web应用程序所使用的技术
  * servlet
  * pls
  * rails
* 会话令牌：
  * JSESSIONID java平台
  * ASPSESSIONID Microsoft IIS服务器
  * ASP.NET_SessionId——Microsoft ASP.NET 
  * CFID/CFTOKEN——Cold Fusion
  * PHPSESSID——PHP

#### 确定服务器端功能

* 略

#### 解析受攻击面

* 客户端确认——越权，数据包伪造
* 数据库交互——SQL注入
* 文件上传与下载——目录遍历，任意文件上传，任意文件下载
* 显示用户提交数据——XSS
* 动态重定向——重定向与消息头注入
* 社交网络功能——用户名枚举、XSS
* 登录——弱口令爆破
* 多阶段登录——逻辑漏洞
* 会话状态——预测令牌、令牌处理不安全
* 访问控制——水平越权、垂直越权
* 明文通信——会话劫持、收集证数和敏感数据
* 错误消息——信息泄露
* 电子邮件交互——电子邮件与命令注入
* 本地代码组件或交互——缓冲区溢出
* 第三方组件——已知漏洞
* 确定Web服务器软件——常见不当配置、已知程序缺陷

